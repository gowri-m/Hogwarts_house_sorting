{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji\n",
    "# !pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8786"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_files = [\"/Users/gowri/Desktop/SI630/project/@grinqotts_user_tweets.xlsx\", \"/Users/gowri/Desktop/SI630/project/@JFroGryffindor_user_tweets.xlsx\",\n",
    "          \"/Users/gowri/Desktop/SI630/project/@GryffindorJenny_user_tweets.xlsx\"]\n",
    "g = []\n",
    "for file in g_files:\n",
    "    g.append(pd.read_excel(file,engine='openpyxl'))\n",
    "    \n",
    "g_df = pd.concat(g, ignore_index=True)\n",
    "g_df = g_df[[\"Text\"]]\n",
    "g_df[\"House\"] = \"Gryffindor\"\n",
    "len(g_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9271"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_files = [\"/Users/gowri/Desktop/SI630/project/@HannahNMadzinga_user_tweets.xlsx\", \"/Users/gowri/Desktop/SI630/project/@HisHufflepuff_user_tweets.xlsx\",\n",
    "          \"/Users/gowri/Desktop/SI630/project/@starpotter90_user_tweets.xlsx\"]\n",
    "h = []\n",
    "for file in h_files:\n",
    "    h.append(pd.read_excel(file,engine='openpyxl'))\n",
    "    \n",
    "h_df = pd.concat(h, ignore_index=True)\n",
    "h_df = h_df[[\"Text\"]]\n",
    "h_df[\"House\"] = \"Hufflepuff\"\n",
    "len(h_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9462"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_files = [\"/Users/gowri/Desktop/SI630/project/@DracoMSlytherin_user_tweets.xlsx\", \"/Users/gowri/Desktop/SI630/project/@_ohkaykaykaaaay_user_tweets.xlsx\",\n",
    "          \"/Users/gowri/Desktop/SI630/project/@SacredSlytherin_user_tweets.xlsx\"]\n",
    "s = []\n",
    "for file in s_files:\n",
    "    s.append(pd.read_excel(file,engine='openpyxl'))\n",
    "    \n",
    "s_df = pd.concat(s, ignore_index=True)\n",
    "s_df = s_df[[\"Text\"]]\n",
    "s_df[\"House\"] = \"Slytherin\"\n",
    "s_df.head(5)\n",
    "len(s_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9576"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_files = [\"/Users/gowri/Desktop/SI630/project/@ravenclaw0044_user_tweets.xlsx\", \"/Users/gowri/Desktop/SI630/project/@softuch25_user_tweets.xlsx\",\n",
    "          \"/Users/gowri/Desktop/SI630/project/@hogwartsIife_user_tweets.xlsx\"]\n",
    "r = []\n",
    "for file in r_files:\n",
    "    r.append(pd.read_excel(file, engine='openpyxl'))\n",
    "    \n",
    "r_df = pd.concat(r, ignore_index=True)\n",
    "r_df = r_df[[\"Text\"]]\n",
    "r_df[\"House\"] = \"Ravenclaw\"\n",
    "len(r_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>House</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>I wish I could just turn off my attraction to men</td>\n",
       "      <td>Slytherin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>*Draco nodded and took @DMalfoysFlower's hand,...</td>\n",
       "      <td>Slytherin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5446</th>\n",
       "      <td>@ArdentResister Thank you ðŸ’œ</td>\n",
       "      <td>Ravenclaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>@BadJewishBoy Pesach?</td>\n",
       "      <td>Ravenclaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>I hate when twitter randomly unfollows ppl.</td>\n",
       "      <td>Ravenclaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>@stargleek1 Fingers crossed I'm going to the H...</td>\n",
       "      <td>Hufflepuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>I'm listening to \"Sail\" by AWOLNATION on Pando...</td>\n",
       "      <td>Gryffindor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>-- be gentle to her, and Draco understood it. ...</td>\n",
       "      <td>Slytherin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>*Draco gently stroked his hand over @DMalfoysF...</td>\n",
       "      <td>Slytherin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>RT @CassidyLWright : Yâ€™all voting for Tr*mp be...</td>\n",
       "      <td>Slytherin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text       House\n",
       "3818  I wish I could just turn off my attraction to men   Slytherin\n",
       "1075  *Draco nodded and took @DMalfoysFlower's hand,...   Slytherin\n",
       "5446                        @ArdentResister Thank you ðŸ’œ   Ravenclaw\n",
       "3266                              @BadJewishBoy Pesach?   Ravenclaw\n",
       "1293        I hate when twitter randomly unfollows ppl.   Ravenclaw\n",
       "8210  @stargleek1 Fingers crossed I'm going to the H...  Hufflepuff\n",
       "5133  I'm listening to \"Sail\" by AWOLNATION on Pando...  Gryffindor\n",
       "2741  -- be gentle to her, and Draco understood it. ...   Slytherin\n",
       "1731  *Draco gently stroked his hand over @DMalfoysF...   Slytherin\n",
       "5641  RT @CassidyLWright : Yâ€™all voting for Tr*mp be...   Slytherin"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([g_df,r_df,s_df,h_df])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37095, 2)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='House', ylabel='Count'>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.histplot(df, x=\"House\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                                    Text       House\n",
       "0     @illicitghosts @extendedhanleia @thorxraqnarok...  Gryffindor\n",
       "1                                  @joeypqcey lana lang  Gryffindor\n",
       "2     RT @buttrbeer : reminder that bi/pan lesbians ...  Gryffindor\n",
       "3                               @oswinpxnd SO true sara  Gryffindor\n",
       "4                layouts - 2021 https://t.co/lO6E1n8sYc  Gryffindor\n",
       "...                                                 ...         ...\n",
       "9266  @iamsilvercloud just a little bit http://t.co/...  Hufflepuff\n",
       "9267  @iamsilvercloud I watched it when I got home f...  Hufflepuff\n",
       "9268  @iamsilvercloud he is trying to be will its funny  Hufflepuff\n",
       "9269  @iamsilvercloud I love it I have watched 3 tim...  Hufflepuff\n",
       "9270  @iamsilvercloud yeah I'm good http://t.co/jk5h...  Hufflepuff\n",
       "\n",
       "[37095 rows x 2 columns]>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @illicitghosts @extendedhanleia @thorxraqnarok...\n",
       "1                                    @joeypqcey lana lang\n",
       "2       RT @buttrbeer : reminder that bi/pan lesbians ...\n",
       "3                                 @oswinpxnd SO true sara\n",
       "4                  layouts - 2021 https://t.co/lO6E1n8sYc\n",
       "                              ...                        \n",
       "9266    @iamsilvercloud just a little bit http://t.co/...\n",
       "9267    @iamsilvercloud I watched it when I got home f...\n",
       "9268    @iamsilvercloud he is trying to be will its funny\n",
       "9269    @iamsilvercloud I love it I have watched 3 tim...\n",
       "9270    @iamsilvercloud yeah I'm good http://t.co/jk5h...\n",
       "Name: Text, Length: 37095, dtype: object"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION,p.OPT.NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    tried to unf but they deactivated ðŸ’€ðŸ’€\n",
       "1                                               lana lang\n",
       "2       RT : reminder that bi/pan lesbians do not exis...\n",
       "3                                            SO true sara\n",
       "4                                               layouts -\n",
       "                              ...                        \n",
       "9266                                    just a little bit\n",
       "9267    I watched it when I got home from work I think...\n",
       "9268                    he is trying to be will its funny\n",
       "9269    I love it I have watched times today I found a...\n",
       "9270                                        yeah I'm good\n",
       "Name: Text, Length: 37095, dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'] = df['Text'].apply(p.clean)\n",
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: re.sub('RT',\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(emoji.demojize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(decontracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        if punctuation != \"_\" :\n",
    "            text = text.replace(punctuation, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'] .apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = TweetTokenizer()\n",
    "# df['Text'] = df['Text'].apply(tt.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Text'] = df['Text'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        tried to unf but they deactivated  skull  skull \n",
       "1                                               lana lang\n",
       "2          reminder that bi pan lesbians do not exist ...\n",
       "3                                            so true sara\n",
       "4                                               layouts  \n",
       "                              ...                        \n",
       "9266                                    just a little bit\n",
       "9267    i watched it when i got home from work i think...\n",
       "9268                    he is trying to be will its funny\n",
       "9269    i love it i have watched times today i found a...\n",
       "9270                                       yeah i am good\n",
       "Name: Text, Length: 37095, dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>House</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1052</th>\n",
       "      <td>awww i love that mug</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>3925</th>\n",
       "      <td>only time iâ€™ll say this  iâ€™m so glad kenny is ...</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>we are recruiting interns for our crime pre...</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>5037</th>\n",
       "      <td>i appreciate your words and concern but i was ...</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>this is the funniest thing i have ever seen</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>2399</th>\n",
       "      <td>draco nodded in agreement with   she had to e...</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>draco is eyes looked into  is eyes and he not...</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>220</th>\n",
       "      <td>the sindi dining hexagon table   woodiessha...</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>good deeds bulawayo lets show some love  he...</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>5441</th>\n",
       "      <td>if you are on the fence about president biden ...</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text       House  label\n",
       "2 1052                             awww i love that mug     Ravenclaw      1\n",
       "1 3925  only time iâ€™ll say this  iâ€™m so glad kenny is ...  Hufflepuff      3\n",
       "  1297     we are recruiting interns for our crime pre...  Hufflepuff      3\n",
       "2 5037  i appreciate your words and concern but i was ...   Ravenclaw      1\n",
       "  7266        this is the funniest thing i have ever seen   Ravenclaw      1\n",
       "3 2399   draco nodded in agreement with   she had to e...   Slytherin      2\n",
       "  2226   draco is eyes looked into  is eyes and he not...   Slytherin      2\n",
       "1 220      the sindi dining hexagon table   woodiessha...  Hufflepuff      3\n",
       "  2058     good deeds bulawayo lets show some love  he...  Hufflepuff      3\n",
       "2 5441  if you are on the fence about president biden ...   Ravenclaw      1"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_small = pd.concat([g_df[:2500],r_df[:2500],s_df[:2500],h_df[:2500]])\n",
    "# df_small.sample(10)\n",
    "df_small = df.groupby('House',as_index=False).apply(lambda s: s.sample(3500))\n",
    "df_small.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gryffindor</th>\n",
       "      <th>0</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hufflepuff</th>\n",
       "      <th>3</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ravenclaw</th>\n",
       "      <th>1</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slytherin</th>\n",
       "      <th>2</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Text\n",
       "House      label      \n",
       "Gryffindor 0      3500\n",
       "Hufflepuff 3      3500\n",
       "Ravenclaw  1      3500\n",
       "Slytherin  2      3500"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.groupby(['House', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gryffindor': 0, 'Ravenclaw': 1, 'Slytherin': 2, 'Hufflepuff': 3}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.House.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['label'] = df_small.House.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>House</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>6400</th>\n",
       "      <td>lestrem lu gmn si   sekolah estetik tp promosi...</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>9190</th>\n",
       "      <td>childish  is make comment like that  seriousl...</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5799</th>\n",
       "      <td>thank you  red_heart</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>3076</th>\n",
       "      <td>remember that  homebru list i am on   star ...</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>981</th>\n",
       "      <td>things you do not need to feel guilty about...</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>7867</th>\n",
       "      <td>bremskieeeee</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>3720</th>\n",
       "      <td>look ma  no windows    gtav  ps4share</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>376</th>\n",
       "      <td>tonight for  superstarfriday on  zifmlockdo...</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>3779</th>\n",
       "      <td>iâ€™d be damn if i pay for a rich manâ€™s nudes wh...</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>7122</th>\n",
       "      <td>ginny weasley is so pretty in ur icon  smiling...</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text       House  label\n",
       "3 6400  lestrem lu gmn si   sekolah estetik tp promosi...   Slytherin      2\n",
       "2 9190   childish  is make comment like that  seriousl...   Ravenclaw      1\n",
       "3 5799                              thank you  red_heart    Slytherin      2\n",
       "1 3076     remember that  homebru list i am on   star ...  Hufflepuff      3\n",
       "2 981      things you do not need to feel guilty about...   Ravenclaw      1\n",
       "3 7867                                       bremskieeeee   Slytherin      2\n",
       "0 3720              look ma  no windows    gtav  ps4share  Gryffindor      0\n",
       "1 376      tonight for  superstarfriday on  zifmlockdo...  Hufflepuff      3\n",
       "3 3779  iâ€™d be damn if i pay for a rich manâ€™s nudes wh...   Slytherin      2\n",
       "2 7122  ginny weasley is so pretty in ur icon  smiling...   Ravenclaw      1"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_small['Text'], df_small.label, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1  8758    3\n",
       "2  8042    1\n",
       "3  6461    2\n",
       "0  1491    0\n",
       "2  3573    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1  8758    my sisters favourite christmas song is on pyjamas\n",
       "2  8042    do not fliss  do you have whatsapp or somethin...\n",
       "3  6461                                         ga ada darah\n",
       "0  1491                                            iâ€™m ready\n",
       "2  3573    go to jail  if a black man can serve years for...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    X_train, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    return_tensors='pt',\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    X_test, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    return_tensors='pt',\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(y_train.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 2\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f77f091b4749469b4cca8c1433d364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=3734.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.9572648627068209\n",
      "Validation loss: 0.8004743028068178\n",
      "F1 Score (Weighted): 0.6875887917137095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=3734.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.6710142210072548\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-397-a2e1be7b6625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training loss: {loss_train_avg}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Validation loss: {val_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-397-a2e1be7b6625>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataloader_val)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1502\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         )\n\u001b[0;32m--> 971\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    566\u001b[0m                 )\n\u001b[1;32m    567\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    569\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "    \n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    mtqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('BERT_epoch_2.model',))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'BERT_epoch_2.model')\n",
    "        \n",
    "tqdm.write(f'\\nEpoch {epoch}')\n",
    "loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "mtqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "tqdm.write(f'Validation loss: {val_loss}')\n",
    "tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "# for train_index, test_index in sss.split(df, df['House']):\n",
    "#     strat_train_set = df.iloc[train_index]\n",
    "#     strat_test_set = df.iloc[test_index]\n",
    "\n",
    "# strat_test_set[\"House\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# conda upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer (stop_words=\"english\",lowercase=True)),\n",
    "                     ('tfidf', TfidfTransformer (use_idf=True,smooth_idf=True)),\n",
    "                     ('clf', MultinomialNB (alpha=1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df.House, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                honestly a mixture of everything  lol\n",
       "1    brownies from hug in a cupcake  smiling_face_w...\n",
       "1    that is going to be a great development in her...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(stop_words='english')),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB(alpha=1))])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(y_test, pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697517854753246"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Gryffindor     0.7509    0.6260    0.6828      1695\n",
      "  Hufflepuff     0.6456    0.7375    0.6885      1867\n",
      "   Ravenclaw     0.6351    0.7392    0.6832      1940\n",
      "   Slytherin     0.8025    0.6761    0.7339      1917\n",
      "\n",
      "    accuracy                         0.6966      7419\n",
      "   macro avg     0.7085    0.6947    0.6971      7419\n",
      "weighted avg     0.7074    0.6966    0.6975      7419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import transformers\n",
    "# from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bert\n",
    "# from bert import run_classifier\n",
    "# from bert import optimization\n",
    "# from bert import tokenization\n",
    "# from bert import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "# import pandas as pd\n",
    "# import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.INFO)\n",
    "# transformers_logger = logging.getLogger(\"transformers\")\n",
    "# transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = ClassificationArgs(num_train_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ClassificationModel(\n",
    "#     'bert',\n",
    "#     'bert-base-cased',\n",
    "#     num_labels=4,\n",
    "#     args=model_args,\n",
    "#     use_cuda = False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab = pd.get_dummies(y_train)\n",
    "# labels_train = lab.values.argmax(1)\n",
    "# labels_train = pd.DataFrame(labels_train)\n",
    "# labels_train.columns = [ \"labels\"]\n",
    "\n",
    "# labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df =  pd.DataFrame(X_train).join(labels_train.set_index(X_train.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab = pd.get_dummies(y_test)\n",
    "# labels_test = lab.values.argmax(1)\n",
    "# labels_test = pd.DataFrame(labels_test)\n",
    "# labels_test.columns = [ \"labels\"]\n",
    "# labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1909     draco nodded and looked between the movies   ...\n",
       "4575    i do not mean to brag  but  10 times my dog ac...\n",
       "1690    live right now   we hit our goal for the famil...\n",
       "5075       if yâ€™all wanna talk about being respectable...\n",
       "3977                                                     \n",
       "                              ...                        \n",
       "556     it is everyone s job to stand up against racis...\n",
       "3119             both he and could need a bit of a rest  \n",
       "4027    you put it out into the universe so there is n...\n",
       "204     i am so sorry  sending you all the love   purp...\n",
       "2720                                            y all    \n",
       "Name: Text, Length: 7419, dtype: object"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df =   pd.DataFrame(X_test).join(labels_test.set_index(X_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([X_train,labels_train],axis=1)\n",
    "# test_df\n",
    "\n",
    "# y= y_train\n",
    "\n",
    "def convert_list(x):\n",
    "    a = []\n",
    "    a.append(x)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.apply(convert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7212    [Gryffindor]\n",
       "7192    [Hufflepuff]\n",
       "6803     [Ravenclaw]\n",
       "2535     [Ravenclaw]\n",
       "1279    [Hufflepuff]\n",
       "            ...     \n",
       "7763    [Gryffindor]\n",
       "6591     [Ravenclaw]\n",
       "8944     [Ravenclaw]\n",
       "206     [Hufflepuff]\n",
       "6939     [Ravenclaw]\n",
       "Name: House, Length: 29676, dtype: object"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1909     [Slytherin]\n",
       "4575    [Hufflepuff]\n",
       "1690     [Ravenclaw]\n",
       "5075     [Slytherin]\n",
       "3977     [Slytherin]\n",
       "            ...     \n",
       "556      [Ravenclaw]\n",
       "3119     [Slytherin]\n",
       "4027     [Ravenclaw]\n",
       "204      [Ravenclaw]\n",
       "2720    [Hufflepuff]\n",
       "Name: House, Length: 7419, dtype: object"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.apply(convert_list)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train,y_train],axis=1)\n",
    "train_df.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test,y_test],axis=1)\n",
    "test_df.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>veterans and gold star families are getting...</td>\n",
       "      <td>[Gryffindor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>literally me when people were mad hemo is p...</td>\n",
       "      <td>[Hufflepuff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>who tf voted  no deactivate</td>\n",
       "      <td>[Ravenclaw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>face_blowing_a_kiss  face_blowing_a_kiss  pur...</td>\n",
       "      <td>[Ravenclaw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>angilwi but you tithe to them  you buy thei...</td>\n",
       "      <td>[Hufflepuff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>days</td>\n",
       "      <td>[Gryffindor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>thank u sascha ily</td>\n",
       "      <td>[Ravenclaw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8944</th>\n",
       "      <td>i just send a tweet saying   when will you not...</td>\n",
       "      <td>[Ravenclaw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>off with your head</td>\n",
       "      <td>[Hufflepuff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>omg you are so pretty  growing_heart</td>\n",
       "      <td>[Ravenclaw]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29676 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        labels\n",
       "7212     veterans and gold star families are getting...  [Gryffindor]\n",
       "7192     literally me when people were mad hemo is p...  [Hufflepuff]\n",
       "6803                      who tf voted  no deactivate     [Ravenclaw]\n",
       "2535   face_blowing_a_kiss  face_blowing_a_kiss  pur...   [Ravenclaw]\n",
       "1279     angilwi but you tithe to them  you buy thei...  [Hufflepuff]\n",
       "...                                                 ...           ...\n",
       "7763                                              days   [Gryffindor]\n",
       "6591                                 thank u sascha ily   [Ravenclaw]\n",
       "8944  i just send a tweet saying   when will you not...   [Ravenclaw]\n",
       "206                                  off with your head  [Hufflepuff]\n",
       "6939              omg you are so pretty  growing_heart    [Ravenclaw]\n",
       "\n",
       "[29676 rows x 2 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing BertweetForMultiLabelSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing BertweetForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertweetForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertweetForMultiLabelSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = MultiLabelClassificationModel('bertweet', 'vinai/bertweet-base', num_labels=4, args={'num_train_epochs': 1,'num_train_epochs': 1,'reprocess_input_data': True},use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6da60219ebe4a55ae0e82d7aba51a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29676.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-44e3b58a00f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/simpletransformers/classification/multi_label_classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, eval_df, output_dir, show_running_loss, args, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     ):\n\u001b[0;32m--> 217\u001b[0;31m         return super().train_model(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mmulti_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m                 \u001b[0mtrain_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         train_dataloader = DataLoader(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/simpletransformers/classification/multi_label_classification_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     ):\n\u001b[0;32m--> 241\u001b[0;31m         return super().load_and_cache_examples(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m             dataset = ClassificationDataset(\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/simpletransformers/classification/classification_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mClassificationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         self.examples, self.labels = build_classification_dataset(\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/simpletransformers/classification/classification_utils.py\u001b[0m in \u001b[0;36mbuild_classification_dataset\u001b[0;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
